{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO9stUPDQ9ljX92Gk/+Abn1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -U -q \"google-generativeai>=0.7.2\""],"metadata":{"id":"MyuowH9_Z9N2","executionInfo":{"status":"ok","timestamp":1731247753947,"user_tz":180,"elapsed":10389,"user":{"displayName":"Diego de Paiva Oliveira","userId":"09514966768139983921"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import google.generativeai as genai"],"metadata":{"id":"C84CG3gAaAhu","executionInfo":{"status":"ok","timestamp":1731248518035,"user_tz":180,"elapsed":411,"user":{"displayName":"Diego de Paiva Oliveira","userId":"09514966768139983921"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)"],"metadata":{"id":"7raXO85saCqy","executionInfo":{"status":"ok","timestamp":1731248521278,"user_tz":180,"elapsed":1960,"user":{"displayName":"Diego de Paiva Oliveira","userId":"09514966768139983921"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n","\n","prompt = \"A rápida raposa marrom salta sobre o cachorro preguiçoso\" * 625\n","\n","quantidade_de_palavras = len(prompt.split())\n","quantidade_de_letras = len(prompt)\n","print('Quantidade de palavras:', quantidade_de_palavras)\n","\n","# Esse método calcula e retorna o número de tokens necessários para processar o prompt.\n","quantidade_de_tokens = model.count_tokens(prompt)\n","\n","print(\"total_tokens: \", quantidade_de_tokens.total_tokens)\n","print(\"palavras por token: \", quantidade_de_palavras/quantidade_de_tokens.total_tokens)\n","print(\"letras por token: \", quantidade_de_letras/quantidade_de_tokens.total_tokens,\"\\n\")\n","\n","\n","response = model.generate_content(prompt)\n","\n","# O metadado usage_metadata normalmente inclui:\n","# prompt_token_count: Número de tokens usados no prompt.\n","# candidates_token_count: Número de tokens usados na resposta gerada pelo modelo.\n","# total_token_count: Número total de tokens usados, que é a soma dos tokens do prompt e da resposta\n","print(response.usage_metadata)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"rB1Tz7xkklct","executionInfo":{"status":"ok","timestamp":1731250628470,"user_tz":180,"elapsed":4578,"user":{"displayName":"Diego de Paiva Oliveira","userId":"09514966768139983921"}},"outputId":"69c302b9-c8f2-4ed4-8906-65d3ffb0fb72"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Quantidade de palavras: 5001\n","total_tokens:  8125\n","palavras por token:  0.6155076923076923\n","letras por token:  4.3076923076923075 \n","\n","prompt_token_count: 8126\n","candidates_token_count: 74\n","total_token_count: 8200\n","\n"]}]},{"cell_type":"code","source":["# Função para gerar um texto com 5000 palavras\n","def gerar_texto_5000_palavras():\n","    texto = \"A rápida raposa marrom salta sobre o cachorro preguiçoso \" * 556  # Gera um texto de 5.000 palavras\n","    return texto\n","\n","# Função para calcular o número de tokens\n","def calcular_tokens(model, texto):\n","    # Contar o número de tokens do texto\n","    return model.count_tokens(texto)\n","\n","# Função para gerar conteúdo e obter metadados\n","def gerar_conteudo_e_analisar(model, texto):\n","    # Gerar conteúdo com base no texto\n","    response = model.generate_content(texto)\n","\n","    # Obter os metadados sobre o uso de tokens\n","    usage_metadata = response.usage_metadata\n","\n","    return response.text, usage_metadata\n","\n","# Instanciar o modelo generativo Gemini\n","model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n","\n","# Gerar um texto com 5000 palavras\n","texto_5000_palavras = gerar_texto_5000_palavras()\n","\n","# Calcular o número de tokens para o texto\n","total_tokens = calcular_tokens(model, texto_5000_palavras)\n","print(f\"Total de tokens para o texto de 5000 palavras: {total_tokens}\")\n","\n","# Gerar o conteúdo e analisar os metadados\n","generated_text, usage_metadata = gerar_conteudo_e_analisar(model, texto_5000_palavras)\n","\n","# Exibir os metadados de uso de tokens\n","print(\"Metadados de uso de tokens:\")\n","print(usage_metadata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"1_iggazXc13i","executionInfo":{"status":"ok","timestamp":1731249388692,"user_tz":180,"elapsed":4503,"user":{"displayName":"Diego de Paiva Oliveira","userId":"09514966768139983921"}},"outputId":"cecf00c0-c046-4315-8dd5-1150049aaac5"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de tokens para o texto de 5000 palavras: total_tokens: 7229\n","\n","Metadados de uso de tokens:\n","prompt_token_count: 7230\n","candidates_token_count: 149\n","total_token_count: 7379\n","\n"]}]}]}